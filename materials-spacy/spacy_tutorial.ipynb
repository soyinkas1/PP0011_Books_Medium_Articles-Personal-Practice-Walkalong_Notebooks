{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x19a4156d6d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a `Doc` object. This is a sequence of `Token` objects representing a `lexical token`\n",
    "Each Token object has information about a particular piece—typically one word—of text. You can instantiate a Doc object by calling the Language object with the input string as an argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "introduction_doc = nlp(\n",
    "    \"This tutorial is about Natural Language Processing in spaCy.\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(introduction_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the Doc object with a list comprehension that produces a series of Token objects. \n",
    "On each Token object, you call the .text attribute to get the text contained within that token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'tutorial',\n",
       " 'is',\n",
       " 'about',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'in',\n",
       " 'spaCy',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the token in Doc\n",
    "[token.text for token in introduction_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'tutorial', 'is', 'about', 'Natural', 'Language', 'Processing', 'in', 'Spacy', '.']\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "file_name = \"introduction.txt\"\n",
    "\n",
    "introduction_doc = nlp(\n",
    "    pathlib.Path(file_name).read_text(encoding=\"utf-8\")\n",
    ")\n",
    "\n",
    "print([token.text for token in introduction_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentence Detection**\n",
    "\n",
    "This is the process of locating where sentences start and end in a given text.\n",
    "\n",
    "In `spaCy`, the `.sents` property is used to extract sentences from the Doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "     \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "about_doc = nlp(about_text)\n",
    "sentences = list(about_doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence : Gus Proto is a Python developer currently working for a London-based Fintech company.\n",
      "Sentence : He is interested in learning Natural Language Processing.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(f'Sentence : {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
