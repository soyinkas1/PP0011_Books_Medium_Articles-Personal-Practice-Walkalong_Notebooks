{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a `Doc` object. This is a sequence of `Token` objects representing a `lexical token`\n",
    "Each Token object has information about a particular piece—typically one word—of text. You can instantiate a Doc object by calling the Language object with the input string as an argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "introduction_doc = nlp(\n",
    "    \"This tutorial is about Natural Language Processing in spaCy.\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(introduction_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the Doc object with a list comprehension that produces a series of Token objects. \n",
    "On each Token object, you call the .text attribute to get the text contained within that token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'tutorial',\n",
       " 'is',\n",
       " 'about',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'in',\n",
       " 'spaCy',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the token in Doc\n",
    "[token.text for token in introduction_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'tutorial', 'is', 'about', 'Natural', 'Language', 'Processing', 'in', 'Spacy', '.']\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "file_name = \"introduction.txt\"\n",
    "\n",
    "introduction_doc = nlp(\n",
    "    pathlib.Path(file_name).read_text(encoding=\"utf-8\")\n",
    ")\n",
    "\n",
    "print([token.text for token in introduction_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentence Detection**\n",
    "\n",
    "This is the process of locating where sentences start and end in a given text.\n",
    "\n",
    "In `spaCy`, the `.sents` property is used to extract sentences from the Doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "     \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "about_doc = nlp(about_text)\n",
    "sentences = list(about_doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(about_doc.sents )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence : Gus Proto is a Python developer currently working for a London-based Fintech company.\n",
      "Sentence : He is interested in learning Natural Language Processing.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(f'Sentence : {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also customize sentence detection behavior by using custom delimiters. Here’s an example where an ellipsis (...) is used as a delimiter, in addition to the full stop, or period (.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipsis_text = (\n",
    "     \"Gus, can you, ... never mind, I forgot\"\n",
    "     \" what I was saying. So, do you think\"\n",
    "     \" we should ...\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component('set_custom_boundaries')\n",
    "def set_custom_boundaries(doc):\n",
    "    \"\"\"Add support to use `...` as delimited for sentence detection\"\"\"\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == '...':\n",
    "            doc[token.i + 1].is_sent_start = True\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus, can you, ...\n",
      "never mind, I forgot what I was saying.\n",
      "So, do you think we should ...\n"
     ]
    }
   ],
   "source": [
    "custom_nlp = spacy.load('en_core_web_sm')\n",
    "custom_nlp.add_pipe('set_custom_boundaries', before='parser')\n",
    "custom_ellipsis_doc = custom_nlp(ellipsis_text)\n",
    "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
    "\n",
    "for sentence in custom_ellipsis_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_ellipsis_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buidling the `Doc` container involces tokeninzing the text. The process of tokenization breats a text  down into its basic units or **tokens** whixch are represented in SpaCy as `Token` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus 0\n",
      "Proto 4\n",
      "is 10\n",
      "a 13\n",
      "Python 15\n",
      "developer 22\n",
      "currently 32\n",
      "working 42\n",
      "for 50\n",
      "a 54\n",
      "London 56\n",
      "- 62\n",
      "based 63\n",
      "Fintech 69\n",
      "company 77\n",
      ". 84\n",
      "He 86\n",
      "is 89\n",
      "interested 92\n",
      "in 103\n",
      "learning 106\n",
      "Natural 115\n",
      "Language 123\n",
      "Processing 132\n",
      ". 142\n"
     ]
    }
   ],
   "source": [
    "# The token’s original index position in the string is still available as an attribute on Token\n",
    "\n",
    "about_doc = nlp(about_text)\n",
    "\n",
    "for token in about_doc:\n",
    "    print(token, token.idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy provides various other `attributes` for the `Token` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with Whitespace  Is Alphabetic?    Is Puntuation?    Is Stop Word?\n",
      "Gus                   True              False             False\n",
      "Proto                 True              False             False\n",
      "is                    True              False             True\n",
      "a                     True              False             True\n",
      "Python                True              False             False\n",
      "developer             True              False             False\n",
      "currently             True              False             False\n",
      "working               True              False             False\n",
      "for                   True              False             True\n",
      "a                     True              False             True\n",
      "London                True              False             False\n",
      "-                     False             True              False\n",
      "based                 True              False             False\n",
      "Fintech               True              False             False\n",
      "company               True              False             False\n",
      ".                     False             True              False\n",
      "He                    True              False             True\n",
      "is                    True              False             True\n",
      "interested            True              False             False\n",
      "in                    True              False             True\n",
      "learning              True              False             False\n",
      "Natural               True              False             False\n",
      "Language              True              False             False\n",
      "Processing            True              False             False\n",
      ".                     False             True              False\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"{\"Text with Whitespace\":22}\"\n",
    "    f\"{\"Is Alphabetic?\":18}\"\n",
    "    f\"{\"Is Puntuation?\":18}\"\n",
    "    f\"{\"Is Stop Word?\"}\"\n",
    "\n",
    "\n",
    ")\n",
    "for token in about_doc:\n",
    "    print(\n",
    "    f\"{str(token.text_with_ws):22}\"\n",
    "    f\"{str(token.is_alpha):18}\"\n",
    "    f\"{str(token.is_punct):18}\"\n",
    "    f\"{str(token.is_stop)}\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with many aspects of spaCy, you can also customize the tokenization process to detect tokens on custom characters. This is often used for hyphenated words such as London-based.\n",
    "\n",
    "To customize tokenization, you need to update the tokenizer property on the callable Language object with a new Tokenizer object.\n",
    "\n",
    "To see what’s involved, imagine you had some text that used the @ symbol instead of the usual hyphen (-) as an infix to link words together. So, instead of London-based, you had London@based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'a', 'London@based', 'Fintech', 'company', '.', 'He']\n"
     ]
    }
   ],
   "source": [
    "custom_about_text = (\n",
    "    \"Gus proto is a Python developer currently\"\n",
    "    \" working for a London@based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing\"\n",
    ")\n",
    "\n",
    "print([token.text for token in nlp(custom_about_text)[8:15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the default parsing read the London@based text as a single token, but if you used a hyphen instead of the @ symbol, then you’d get three tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'a', 'London', '-', 'based', 'Fintech', 'company']\n"
     ]
    }
   ],
   "source": [
    "custom_about_text = (\n",
    "    \"Gus proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing\"\n",
    ")\n",
    "\n",
    "print([token.text for token in nlp(custom_about_text)[8:15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'a', 'London', '-', 'based', 'Fintech', 'company']\n"
     ]
    }
   ],
   "source": [
    "# To include the @ symbol as a custom infix, you need to build your own Tokenizer object\n",
    "import re\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
    "prefix_re = spacy.util.compile_prefix_regex(\n",
    "    custom_nlp.Defaults.prefixes\n",
    ")\n",
    "suffix_re = spacy.util.compile_suffix_regex(\n",
    "    custom_nlp.Defaults.suffixes\n",
    ")\n",
    "\n",
    "custom_infixes = [r\"@\"]\n",
    "\n",
    "infix_re = spacy.util.compile_infix_regex(\n",
    "    list(custom_nlp.Defaults.infixes) + custom_infixes\n",
    ")\n",
    "\n",
    "custom_nlp.tokenizer = Tokenizer(\n",
    "    nlp.vocab,\n",
    "    prefix_search=prefix_re.search,\n",
    "    suffix_search=suffix_re.search,\n",
    "    infix_finditer=infix_re.finditer,\n",
    "    token_match=None\n",
    ")\n",
    "\n",
    "custom_tokenizer_about_doc = custom_nlp(custom_about_text)\n",
    "\n",
    "print([token.text for token in custom_tokenizer_about_doc[8:15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop Words**\n",
    "\n",
    "`Stop words` are typically defined as the most common words in a language. In the English language, some examples of stop words are the, are, but, and they. Most sentences need to contain stop words in order to be full sentences that make grammatical sense\n",
    "\n",
    "With NLP, stop words are generally removed because they aren’t significant, and they heavily distort any word frequency analysis. spaCy stores a list of stop words for the English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "len(spacy_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n",
      "about\n",
      "otherwise\n",
      "last\n",
      "’m\n",
      "been\n",
      "‘s\n",
      "whose\n",
      "doing\n",
      "out\n"
     ]
    }
   ],
   "source": [
    "for stop_word in list(spacy_stopwords)[:10]:\n",
    "    print(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gus', 'Proto', 'Python', 'developer', 'currently', 'working', 'London', '-', 'based', 'Fintech', 'company', '.', 'interested', 'learning', 'Natural', 'Language', 'Processing', '.']\n"
     ]
    }
   ],
   "source": [
    "# You can remove stop words from the input text by making use of the .is_stop attribute of each token\n",
    "print([token.text for token in about_doc if not token.is_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you can’t be sure exactly what the sentence is trying to say without stop words, you still have a lot of information about what it’s generally about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization**\n",
    "\n",
    "`Lemmatization` is the process of reducing inflected forms of a word while still ensuring that the reduced form belongs to the language. This reduced form, or root word, is called a **lemma**\n",
    "\n",
    "For example `organise` is the lemma for `organises` , `organised` and `organising`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  is : be\n",
      "             helping : help\n",
      "               keeps : keep\n",
      "          organising : organise\n",
      "             meetups : meetup\n",
      "               talks : talk\n"
     ]
    }
   ],
   "source": [
    "# spaCy puts `lemma_` attribute om the `Token` class\n",
    "conference_help_text = (\n",
    "    \"Gus is helping organise a developer\"\n",
    "    \" conference on Application of Natural Language\"\n",
    "    \" Processing. he keeps organising local Python meetups\"\n",
    "    \" and several internal talks at his workplace\"\n",
    "\n",
    ")\n",
    "\n",
    "conference_help_doc = nlp(conference_help_text)\n",
    "for token in conference_help_doc:\n",
    "    if str(token) != str(token.lemma_):\n",
    "        print(f\"{str(token):>20} : {str(token.lemma_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization helps you avoid duplicate words that may overlap conceptually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Frequency**\n",
    "\n",
    "You can now convert a given text into tokens and perform statistical analysis on it. This analysis can give you various insights, such as common words or unique words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gus', 4), ('London', 3), ('Natural', 3), ('Language', 3), ('Processing', 3)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "complete_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech company. He is\"\n",
    "    \" interested in learning Natural Language Processing.\"\n",
    "    \" There is a developer conference happening on 21 July\"\n",
    "    ' 2019 in London. It is titled \"Applications of Natural'\n",
    "    ' Language Processing\". There is a helpline number'\n",
    "    \" available at +44-1234567891. Gus is helping organize it.\"\n",
    "    \" He keeps organizing local Python meetups and several\"\n",
    "    \" internal talks at his workplace. Gus is also presenting\"\n",
    "    ' a talk. The talk will introduce the reader about \"Use'\n",
    "    ' cases of Natural Language Processing in Fintech\".'\n",
    "    \" Apart from his work, he is very passionate about music.\"\n",
    "    \" Gus is learning to play the Piano. He has enrolled\"\n",
    "    \" himself in the weekend batch of Great Piano Academy.\"\n",
    "    \" Great Piano Academy is situated in Mayfair or the City\"\n",
    "    \" of London and has world-class piano instructors.\"\n",
    "    )\n",
    "\n",
    "complete_doc = nlp(complete_text)\n",
    "\n",
    "words = [\n",
    "    token.text for token in complete_doc\n",
    "    if not token.is_stop and not token.is_punct\n",
    "]\n",
    "\n",
    "print(Counter(words).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('is', 10), ('a', 5), ('in', 5), ('Gus', 4), ('of', 4)]\n"
     ]
    }
   ],
   "source": [
    "# Without removing stop words\n",
    "\n",
    "words = [\n",
    "    token.text for token in complete_doc\n",
    "    if not token.is_punct\n",
    "]\n",
    "\n",
    "print(Counter(words).most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four out of five of the most common words are stop words that don’t really tell you much about the summarized text. This is why stop words are often considered noise for many applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part of Speech Tagging**\n",
    "\n",
    "`Part of speech` or `POS` is a grammatical role that explains how a particular word is used in a sentence. There are typically eight parts of speech:\n",
    "\n",
    "1. Noun\n",
    "2. Pronoun\n",
    "3. Adjective\n",
    "4. Verb\n",
    "5. Adverb\n",
    "6. Preposition\n",
    "7. Conjunction\n",
    "8. Interjection\n",
    "\n",
    "`Part-of-speech tagging` is the process of assigning a POS tag to each token depending on its usage in the sentence. POS tags are useful for assigning a syntactic category like noun or verb to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    TOKEN: Gus\n",
      "    =======\n",
      "    TAG: NNP        POS: PROPN\n",
      "    EXPLANATION: noun, proper singular\n",
      "\n",
      "    TOKEN: Proto\n",
      "    =======\n",
      "    TAG: NNP        POS: PROPN\n",
      "    EXPLANATION: noun, proper singular\n",
      "\n",
      "    TOKEN: is\n",
      "    =======\n",
      "    TAG: VBZ        POS: AUX\n",
      "    EXPLANATION: verb, 3rd person singular present\n",
      "\n",
      "    TOKEN: a\n",
      "    =======\n",
      "    TAG: DT         POS: DET\n",
      "    EXPLANATION: determiner\n",
      "\n",
      "    TOKEN: Python\n",
      "    =======\n",
      "    TAG: NNP        POS: PROPN\n",
      "    EXPLANATION: noun, proper singular\n",
      "\n",
      "    TOKEN: developer\n",
      "    =======\n",
      "    TAG: NN         POS: NOUN\n",
      "    EXPLANATION: noun, singular or mass\n",
      "\n",
      "    TOKEN: currently\n",
      "    =======\n",
      "    TAG: RB         POS: ADV\n",
      "    EXPLANATION: adverb\n",
      "\n",
      "    TOKEN: working\n",
      "    =======\n",
      "    TAG: VBG        POS: VERB\n",
      "    EXPLANATION: verb, gerund or present participle\n",
      "\n",
      "    TOKEN: for\n",
      "    =======\n",
      "    TAG: IN         POS: ADP\n",
      "    EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "    TOKEN: a\n",
      "    =======\n",
      "    TAG: DT         POS: DET\n",
      "    EXPLANATION: determiner\n",
      "\n",
      "    TOKEN: London\n",
      "    =======\n",
      "    TAG: NNP        POS: PROPN\n",
      "    EXPLANATION: noun, proper singular\n",
      "\n",
      "    TOKEN: -\n",
      "    =======\n",
      "    TAG: HYPH       POS: PUNCT\n",
      "    EXPLANATION: punctuation mark, hyphen\n",
      "\n",
      "    TOKEN: based\n",
      "    =======\n",
      "    TAG: VBN        POS: VERB\n",
      "    EXPLANATION: verb, past participle\n",
      "\n",
      "    TOKEN: Fintech\n",
      "    =======\n",
      "    TAG: NNP        POS: PROPN\n",
      "    EXPLANATION: noun, proper singular\n",
      "\n",
      "    TOKEN: company\n",
      "    =======\n",
      "    TAG: NN         POS: NOUN\n",
      "    EXPLANATION: noun, singular or mass\n",
      "\n",
      "    TOKEN: .\n",
      "    =======\n",
      "    TAG: .          POS: PUNCT\n",
      "    EXPLANATION: punctuation mark, sentence closer\n",
      "\n",
      "    TOKEN: He\n",
      "    =======\n",
      "    TAG: PRP        POS: PRON\n",
      "    EXPLANATION: pronoun, personal\n",
      "\n",
      "    TOKEN: is\n",
      "    =======\n",
      "    TAG: VBZ        POS: AUX\n",
      "    EXPLANATION: verb, 3rd person singular present\n",
      "\n",
      "    TOKEN: interested\n",
      "    =======\n",
      "    TAG: JJ         POS: ADJ\n",
      "    EXPLANATION: adjective (English), other noun-modifier (Chinese)\n",
      "\n",
      "    TOKEN: in\n",
      "    =======\n",
      "    TAG: IN         POS: ADP\n",
      "    EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "    TOKEN: learning\n",
      "    =======\n",
      "    TAG: VBG        POS: VERB\n",
      "    EXPLANATION: verb, gerund or present participle\n",
      "\n",
      "    TOKEN: Natural\n",
      "    =======\n",
      "    TAG: NNP        POS: PROPN\n",
      "    EXPLANATION: noun, proper singular\n",
      "\n",
      "    TOKEN: Language\n",
      "    =======\n",
      "    TAG: NNP        POS: PROPN\n",
      "    EXPLANATION: noun, proper singular\n",
      "\n",
      "    TOKEN: Processing\n",
      "    =======\n",
      "    TAG: NNP        POS: PROPN\n",
      "    EXPLANATION: noun, proper singular\n",
      "\n",
      "    TOKEN: .\n",
      "    =======\n",
      "    TAG: .          POS: PUNCT\n",
      "    EXPLANATION: punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "for token in about_doc:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    TOKEN: {str(token)}\n",
    "    =======\n",
    "    TAG: {str(token.tag_):10} POS: {token.pos_}\n",
    "    EXPLANATION: {spacy.explain(token.tag_)}\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([developer, company], [interested])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By using POS tags, you can extract a particular category of words:\n",
    "nouns = []\n",
    "adjectives = []\n",
    "for token in about_doc:\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        nouns.append(token)\n",
    "    if token.pos_ == \"ADJ\":\n",
    "        adjectives.append(token)\n",
    "\n",
    "nouns, adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this type of word classification to derive insights. For instance, you could gauge sentiment by analyzing which adjectives are most commonly used alongside nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\Documents\\PERSONAL\\PERSONAL DEVELOPMENT\\DATA SCIENCE\\Books, Medium.com articles, Documentations practice ipynb notebooks\\venv\\Lib\\site-packages\\spacy\\displacy\\__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"edd47ae431084e6d903c9cb6bee04f06-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">interested</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Natural</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Processing.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-edd47ae431084e6d903c9cb6bee04f06-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-edd47ae431084e6d903c9cb6bee04f06-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-edd47ae431084e6d903c9cb6bee04f06-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-edd47ae431084e6d903c9cb6bee04f06-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-edd47ae431084e6d903c9cb6bee04f06-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-edd47ae431084e6d903c9cb6bee04f06-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-edd47ae431084e6d903c9cb6bee04f06-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-edd47ae431084e6d903c9cb6bee04f06-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-edd47ae431084e6d903c9cb6bee04f06-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-edd47ae431084e6d903c9cb6bee04f06-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-edd47ae431084e6d903c9cb6bee04f06-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-edd47ae431084e6d903c9cb6bee04f06-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-edd47ae431084e6d903c9cb6bee04f06-0-6\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-edd47ae431084e6d903c9cb6bee04f06-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "about_interested_text = (\n",
    "    \"He is interested in learning Natural Language Processing.\"\n",
    ")\n",
    "about_interest_doc = nlp(about_interested_text)\n",
    "displacy.serve(about_interest_doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ab7794fdfcdb440084d6e5c1e21c2eee-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">interested</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Natural</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Processing.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-6\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ab7794fdfcdb440084d6e5c1e21c2eee-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(about_interest_doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
